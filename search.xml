<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>机器学习实践——多元线性回归</title>
    <url>/2021/07/25/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5%E2%80%94%E2%80%94%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</url>
    <content><![CDATA[<h2 id="数据集来源">数据集来源</h2>
<p>数据集来自Kaggle的机器学习入门题目--<a href="https://www.kaggle.com/c/titanic/overview">Titanic</a>。这道题目本来应该用分类器算法进行预测，考虑到只是用来入门，所以就用在了线性回归的实践之中，在最后的输出使用阈值法即可。</p>
<h2 id="数据预处理">数据预处理</h2>
<h3 id="读取数据-验证数据完整性">1.读取数据 &amp; 验证数据完整性</h3>
<p>数据不一定都是完整的，可能会有空数据的存在：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 读取数据</span></span><br><span class="line">train = pd.read_csv(<span class="string">&#x27;data/train.csv&#x27;</span>) </span><br><span class="line"><span class="comment"># 查看数据信息</span></span><br><span class="line"><span class="built_in">print</span>(train.info())</span><br></pre></td></tr></table></figure>
<h3 id="填充空数据">2.填充空数据</h3>
<p>经过上一步的验证得知，Titanic训练集中，年龄、舱号和登船地点三项存在空数据，舱号都以类似于“C23”、“D45”这种形式出现，我认为对于最终预测结果帮助不大，不会使用舱号作为属性，故只需考虑填充年龄和登船地点中的空数据。此处我采用了<strong>中位数</strong>作为年龄填充的依据，<strong>众数</strong>作为登船地点填充的依据：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 年龄填充</span></span><br><span class="line">train[<span class="string">&#x27;Age&#x27;</span>] = train[<span class="string">&#x27;Age&#x27;</span>].fillna(train[<span class="string">&#x27;Age&#x27;</span>].median()) </span><br><span class="line"><span class="comment"># 登船地点填充</span></span><br><span class="line">emb = train[<span class="string">&#x27;Embarked&#x27;</span>].value_counts()</span><br><span class="line">fillstr = emb.idxmax(axis=<span class="number">1</span>)</span><br><span class="line">train[<span class="string">&#x27;Embarked&#x27;</span>] = train[<span class="string">&#x27;Embarked&#x27;</span>].fillna(fillstr)</span><br></pre></td></tr></table></figure>
<h3 id="数据数字化表示">3.数据数字化表示</h3>
<p>数据集中，性别和登船地点是使用字符记录的，所以我们需要将其转换为数字表示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 性别数字化表示</span></span><br><span class="line">train.loc[train[<span class="string">&quot;Sex&quot;</span>] == <span class="string">&quot;male&quot;</span>, <span class="string">&quot;Sex&quot;</span>] = <span class="number">0</span></span><br><span class="line">train.loc[train[<span class="string">&quot;Sex&quot;</span>] == <span class="string">&quot;female&quot;</span>, <span class="string">&quot;Sex&quot;</span>] = <span class="number">1</span></span><br><span class="line"><span class="comment"># 登船地点数字化表示</span></span><br><span class="line">train.loc[train[<span class="string">&#x27;Embarked&#x27;</span>] == <span class="string">&#x27;C&#x27;</span>, <span class="string">&#x27;Embarked&#x27;</span>] = <span class="number">0</span></span><br><span class="line">train.loc[train[<span class="string">&#x27;Embarked&#x27;</span>] == <span class="string">&#x27;Q&#x27;</span>, <span class="string">&#x27;Embarked&#x27;</span>] = <span class="number">1</span></span><br><span class="line">train.loc[train[<span class="string">&#x27;Embarked&#x27;</span>] == <span class="string">&#x27;S&#x27;</span>, <span class="string">&#x27;Embarked&#x27;</span>] = <span class="number">2</span></span><br></pre></td></tr></table></figure>
<h3 id="特征缩放特征归一化">4.特征缩放（特征归一化）</h3>
<p>为了不影响预测结果，需要对不同特征的数据进行归一化处理，特征归一化的公式如下： <span class="math display">\[
x_{n}=\frac{x_{n}-\mu _{n}}{s_{n}}
\]</span> 其中， <span class="math inline">\(\mu _{n}\)</span>​​代表平均值， $ s_{n} $​​​​代表标准差，代码实现如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 选择需要的特征列（具有主观性）</span></span><br><span class="line">x = train[[<span class="string">&quot;Pclass&quot;</span>, <span class="string">&quot;Age&quot;</span>, <span class="string">&quot;Parch&quot;</span>, <span class="string">&quot;Fare&quot;</span>, <span class="string">&quot;Sex&quot;</span>, <span class="string">&quot;Embarked&quot;</span>]]</span><br><span class="line"><span class="comment"># 计算平均值、标准差</span></span><br><span class="line">avg = np.zeros(x.shape[<span class="number">1</span>])</span><br><span class="line">std = np.zeros(x.shape[<span class="number">1</span>])</span><br><span class="line"><span class="comment"># 特征归一化</span></span><br><span class="line">x_norm = (x - avg) / std</span><br></pre></td></tr></table></figure>
<h2 id="代价函数">代价函数</h2>
<p>多元线性回归的代价函数定义如下： <span class="math display">\[
J\left(\theta_{0}, \theta_{1} \ldots \theta_{n}\right)=\frac{1}{2 m} \sum_{i=1}^{m}\left(h_{\theta}\left(x^{(i)}\right)-y^{(i)}\right)^{2}
\]</span></p>
<p><span class="math display">\[
h_{\theta}(x)=\theta_{0}+\theta_{1} x_{1}+\theta_{2} x_{2}+\ldots+\theta_{n} x_{n}
\]</span></p>
<p>其中，上角标代表第<span class="math inline">\(i\)</span>​个数据，下角标代表每个数据的第$ j $​个属性。</p>
<p>代码实现如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cost</span>(<span class="params">x, y, theta</span>):</span></span><br><span class="line">    m = x.shape[<span class="number">0</span>] <span class="comment"># 数据个数</span></span><br><span class="line">    cost = <span class="number">1</span>/<span class="number">2</span>*m*np.<span class="built_in">sum</span>(np.power(x.dot(theta) - y, <span class="number">2</span>))</span><br><span class="line">    <span class="keyword">return</span> cost</span><br></pre></td></tr></table></figure>
<h2 id="梯度下降">梯度下降</h2>
<p>梯度下降的更新公式如下： <span class="math display">\[
\theta_{\mathrm{j}}:=\theta_{\mathrm{j}}-\alpha \frac{\partial}{\partial \theta_{\mathrm{j}}} \frac{1}{2 \mathrm{~m}} \sum_{\mathrm{i}=1}^{\mathrm{m}}\left(\mathrm{h}_{\theta}\left(\mathrm{x}^{(\mathrm{i})}\right)-\mathrm{y}^{(\mathrm{i})}\right)^{2}
\]</span> 求导数后得到： <span class="math display">\[
\theta_{j}:=\theta_{j}-\alpha \frac{1}{m} \sum_{i=1}^{m}\left(\left(h_{\theta}\left(x^{(i)}\right)-y^{(i)}\right) \cdot x_{j}^{(i)}\right)
\]</span> 代码实现如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradientDescent</span>(<span class="params">x, y, theta, alpha, num_iters</span>):</span></span><br><span class="line">    m = x.shape[<span class="number">0</span>] <span class="comment"># 数据个数</span></span><br><span class="line">    cost_history = np.zeros(num_iters) <span class="comment"># 记录每次梯度下降后的误差</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_iters):</span><br><span class="line">        theta = theta - alpha/m*np.dot(x.T, (x.dot(theta) - y))</span><br><span class="line">        cost_history[i] = cost(x, y, theta)</span><br><span class="line">    <span class="keyword">return</span> theta, cost_history</span><br></pre></td></tr></table></figure>
<h2 id="开始训练">开始训练</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">alpha = <span class="number">0.2</span> <span class="comment"># 学习率</span></span><br><span class="line">iters = <span class="number">100</span> <span class="comment">#迭代次数</span></span><br><span class="line">[theta, cost_history] = gradientDescent(x_norm, y_train, theta, alpha, iters)</span><br></pre></td></tr></table></figure>
<h2 id="保存结果">保存结果</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">result = x_norm.dot(theta)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(result)): <span class="comment"># 使用阈值法将结果二值化，以满足二分类的需求</span></span><br><span class="line">    <span class="keyword">if</span> result[i] &gt;= <span class="number">0.5</span>:</span><br><span class="line">        result[i] = <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        result[i] = <span class="number">0</span></span><br></pre></td></tr></table></figure>
<h2 id="计算模型在训练集上的准确率">计算模型在训练集上的准确率</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">num_correct = <span class="number">0</span> <span class="comment"># 统计预测正确个数</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(result)):</span><br><span class="line">    <span class="keyword">if</span> result[i] == y[i]:</span><br><span class="line">        num_correct += <span class="number">1</span></span><br><span class="line">accuracy_train = num_correct / <span class="built_in">len</span>(result)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;在训练集上的正确率为：&#x27;</span>+<span class="built_in">str</span>(accuracy_train))</span><br></pre></td></tr></table></figure>
<h2 id="测试集数据预处理归一化">测试集数据预处理+归一化</h2>
<p>方法同训练集。</p>
<h2 id="保存预测结果-导出kaggle要求的格式的文件">保存预测结果 &amp; 导出Kaggle要求的格式的文件</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">result = x_test.dot(theta) <span class="comment"># 保存结果</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(result)):</span><br><span class="line">    <span class="keyword">if</span> result[i] &gt;= <span class="number">0.5</span>:</span><br><span class="line">        result[i] = <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        result[i] = <span class="number">0</span></span><br><span class="line">        </span><br><span class="line">passengerId = test[<span class="string">&#x27;PassengerId&#x27;</span>].values.reshape(-<span class="number">1</span>, <span class="number">1</span>) <span class="comment"># 导出文件</span></span><br><span class="line"><span class="built_in">list</span> = np.hstack((passengerId, result))</span><br><span class="line">column = [<span class="string">&#x27;PassengerId&#x27;</span>, <span class="string">&#x27;Survived&#x27;</span>]</span><br><span class="line">resultFile = pd.DataFrame(columns=column, data=<span class="built_in">list</span>)</span><br><span class="line">resultFile.to_csv(<span class="string">&#x27;data/submission.csv&#x27;</span>, index=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<h2 id="总结">总结</h2>
<p>经过上述过程，最终在训练集上准确率为79.3%，在测试集上准确率为76.8%。可以改进之处我觉得有两个方面，一方面是对于特征的分析和选择，另一方面就是方法，使用专门的分类器算法势必会让准确率有所提升。</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>线性回归</tag>
      </tags>
  </entry>
</search>
